{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read one of the datasets\n",
    "df = pd.read_csv('../datasets/Dataset1.csv')\n",
    "\n",
    "# Prepare some variables for later use\n",
    "df['treated'] = (df['exposure'] >= 0.25).astype(int)\n",
    "treatedcol = 'treated'\n",
    "vname1 = 'cov_1'\n",
    "vname2 = 'cov_2'\n",
    "col_names = [vname1, vname2]\n",
    "cols = [0, 1]\n",
    "tr = df[df['treated'] == 1][col_names].to_numpy()\n",
    "ct = df[df['treated'] == 0][col_names].to_numpy()\n",
    "n_tr = len(tr)\n",
    "n_ct = len(ct)\n",
    "dropcols = ['id', 'risk', 'exposure', 'outcome', 'Unnamed..0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# Defining the R script for calling CEM, and loading the instance in Python\n",
    "r = robjects.r\n",
    "r['source']('call_cem.r')\n",
    "\n",
    "# Default values, filled out with values from histogram binning further down\n",
    "delta_1 = 0\n",
    "delta_2 = 0\n",
    "stats_1 = np.inf\n",
    "stats_2 = np.inf\n",
    "max_tr_unmatched = 0\n",
    "max_ct_unmatched = 0\n",
    "\n",
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "  df_r = robjects.conversion.py2rpy(df)\n",
    "\n",
    "  # Call R-script for overall imbalance and statistics before stratification\n",
    "  overall_imbalance = robjects.globalenv['overall_imbalance']\n",
    "  vars = robjects.StrVector([i for i in col_names])\n",
    "  overall_res = overall_imbalance(df_r, treatedcol, vars)\n",
    "  print('Overall imbalance')\n",
    "  print(overall_res)\n",
    "\n",
    "  overall_statistics = overall_res.rx2('tab')['statistic']\n",
    "  stats_1 = overall_statistics[vars[0]]\n",
    "  stats_2 = overall_statistics[vars[1]]\n",
    "\n",
    "  # Call R-script for hisogram binning\n",
    "  call_plain_cem = robjects.globalenv['call_plain_cem']\n",
    "  plain_mat = call_plain_cem(df_r, treatedcol, dropcols)\n",
    "  print('Histogram binning')\n",
    "  print(plain_mat)\n",
    "  print(plain_mat.rx2('breaks'))\n",
    "\n",
    "  delta_1 = np.max(np.diff(plain_mat.rx2('breaks').rx2(vname1)))\n",
    "  delta_2 = np.max(np.diff(plain_mat.rx2('breaks').rx2(vname2)))  \n",
    "  max_tr_unmatched = plain_mat.rx2('tab')[2, 1]\n",
    "  max_ct_unmatched = plain_mat.rx2('tab')[2, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter type P1 or P2 from the paper, and also P3 not included in paper.\n",
    "P = 2\n",
    "\n",
    "if (max_tr_unmatched > len(tr)):\n",
    "    max_tr_unmatched = len(tr)\n",
    "\n",
    "if (max_ct_unmatched > len(ct)):\n",
    "    max_ct_unmatched = len(ct)\n",
    "\n",
    "if P == 3:\n",
    "    if (n_tr < n_ct):\n",
    "        max_ct_unmatched = round(n_ct / n_tr)\n",
    "        max_tr_unmatched = 1\n",
    "    else:\n",
    "        max_tr_unmatched = round(n_tr / n_ct)\n",
    "        max_ct_unmatched = 1\n",
    "\n",
    "# For P2, the maximum allowed stratum widths are set to infinity\n",
    "if P == 2:\n",
    "    delta_1 = np.inf\n",
    "    delta_2 = np.inf\n",
    "\n",
    "# The maximum allowed stratum widths for the covariates\n",
    "deltas = [delta_1, delta_2]\n",
    "\n",
    "print(f'Max unmatched G0: {max_ct_unmatched} G1: {max_tr_unmatched}')\n",
    "print(f'Max widths {vname1}: {delta_1}, {vname2}: {delta_2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from numba import njit\n",
    "from numba.core import types\n",
    "from numba.typed import Dict, List\n",
    "\n",
    "four_floats_tuple = types.UniTuple(types.float64, 4)\n",
    "two_floats_tuple = types.UniTuple(types.float64, 2)\n",
    "\n",
    "def potential_edges(tr, ct, cols):\n",
    "    '''Gets the potential stratum edges for the given column indices.'''\n",
    "    edges = []\n",
    "    data = np.concatenate((tr, ct))\n",
    "    for col in cols:\n",
    "        col_data = np.unique(data[:, col]) # also sorts\n",
    "\n",
    "        # Move the leftmost edge to the left by half the distance to the \n",
    "        # closest value to the right\n",
    "        leftmost_edge = col_data[0]\n",
    "        second_leftmost_value = col_data[1]\n",
    "        leftmost_edge = leftmost_edge - abs(leftmost_edge - second_leftmost_value) / 2.\n",
    "        edges.append((col, leftmost_edge))\n",
    "\n",
    "        # Move each edge to the left to the middle between two adjecent values\n",
    "        for i in range(1, len(col_data)):\n",
    "            adjusted_edge = col_data[i] - abs(col_data[i] - col_data[i-1]) / 2.\n",
    "            edges.append((col, adjusted_edge))\n",
    "        \n",
    "        # Add a rightmost edge with a distance equal to half the distance \n",
    "        # between the last and next last values for the column.\n",
    "        rightmost_value = col_data[-1] \n",
    "        second_rightmost_value = col_data[-2]\n",
    "        rightmost_edge = rightmost_value + abs(rightmost_value - second_rightmost_value) / 2.\n",
    "        edges.append((col, rightmost_edge))\n",
    "    return edges\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def faster_count(edges_0, edges_1, tr, ct, unmatched_counts: Dict):\n",
    "    '''Count the number of unmatched for the strata between the edges'''\n",
    "    tr_unmatched = np.float64(0.0)\n",
    "    ct_unmatched = np.float64(0.0)\n",
    "    n_edges_0 = len(edges_0)\n",
    "    n_edges_1 = len(edges_1)\n",
    "    checked_keys = List()\n",
    "\n",
    "    left_0 = edges_0[0]\n",
    "    for i in range(1, n_edges_0):\n",
    "        right_0 = edges_0[i]\n",
    "        left_1 = edges_1[0]\n",
    "        for j in range(1, n_edges_1):\n",
    "            right_1 = edges_1[j]\n",
    "            key = (left_0, right_0, left_1, right_1)\n",
    "            checked_keys.append(key)\n",
    "            if key in unmatched_counts:\n",
    "                counts = unmatched_counts[key]\n",
    "            else:\n",
    "                tr_s = tr[np.where(np.logical_and(\n",
    "                    np.logical_and(tr[:, 0] >= left_0, tr[:, 0] < right_0), \n",
    "                    np.logical_and(tr[:, 1] >= left_1, tr[:, 1] < right_1)))]\n",
    "                ct_s = ct[np.where(np.logical_and(\n",
    "                    np.logical_and(ct[:, 0] >= left_0, ct[:, 0] < right_0), \n",
    "                    np.logical_and(ct[:, 1] >= left_1, ct[:, 1] < right_1)))]\n",
    "                counts = (len(tr_s), len(ct_s))\n",
    "                unmatched_counts[key] = counts\n",
    "            if counts[0] > 0 and counts[1] == 0:\n",
    "                tr_unmatched += counts[0]\n",
    "            elif counts[0] == 0 and counts[1] > 0:\n",
    "                ct_unmatched += counts[1]\n",
    "            left_1 = right_1\n",
    "        left_0 = right_0  \n",
    "  \n",
    "    return (tr_unmatched, ct_unmatched, checked_keys)\n",
    "\n",
    "\n",
    "def count_unmatched(df_edges, tr, ct, unmatched_counts: Dict):\n",
    "    '''Count number of unmatched treated and controls'''\n",
    "    df = df_edges\n",
    "\n",
    "    # Currently only two columns\n",
    "    edges_0 = df[df['col'] == 0]['val'].to_numpy()\n",
    "    edges_1 = df[df['col'] == 1]['val'].to_numpy()\n",
    "\n",
    "    tr_unmatched, ct_unmatched, checked_keys = faster_count(edges_0, edges_1, tr, ct, unmatched_counts)\n",
    "\n",
    "    return int(tr_unmatched), int(ct_unmatched), checked_keys\n",
    "\n",
    "\n",
    "def df_no_outl(df, c):\n",
    "    '''Filter out outlier values, i.e., |z| < 3'''\n",
    "    return df[(np.abs(stats.zscore(df[c])) < 3)][c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_edges = potential_edges(tr, ct, cols)\n",
    "df_edge_candidates = pd.DataFrame(candidate_edges, columns=['col', 'val'])\n",
    "df_edges = df_edge_candidates.copy()\n",
    "\n",
    "cur_tr_match_inc: int = -1\n",
    "cur_tr_match_inc: int = -1\n",
    "remove_index: int\n",
    "selected_edge_width: float\n",
    "\n",
    "col_widths = []\n",
    "for c in col_names:\n",
    "    df_hat = df_no_outl(df, c)\n",
    "    w = np.abs(df_hat.max() - df_hat.min())\n",
    "    col_widths.append(w)\n",
    "\n",
    "col_widths = np.array(col_widths, dtype=np.float64)\n",
    "col_scale_factor = col_widths\n",
    "\n",
    "# Cache for already counted strata results that can be reused\n",
    "unmatched_counts = Dict.empty(key_type=four_floats_tuple, value_type=two_floats_tuple)\n",
    "\n",
    "cur_tr_unmatched, cur_ct_unmatched, _ = count_unmatched(df_edges, tr, ct, unmatched_counts)\n",
    "\n",
    "print(f'Initial unmatched: G0: {cur_ct_unmatched} G1: {cur_tr_unmatched}')\n",
    "print(f'Column maximum widths: {col_widths}')\n",
    "print(f'Column scale factors: {col_scale_factor}')\n",
    "\n",
    "while (len(df_edges) > 0 and (cur_tr_unmatched > max_tr_unmatched or cur_ct_unmatched > max_ct_unmatched)):\n",
    "    selected_edge_width = np.inf\n",
    "    cur_rel_inc = -1\n",
    "    cur_tr_match_inc = -1\n",
    "    cur_ct_match_inc = -1\n",
    "    remove_index = None\n",
    "\n",
    "    for col, col_name in enumerate(col_names):\n",
    "        # Get candidate edges for current column\n",
    "        df_col_edges = df_edges[df_edges['col'] == col]\n",
    "        \n",
    "        for i in range(1, len(df_col_edges) - 1): # Leftmost and rightmost edge will not be removed\n",
    "            assess_val = df_col_edges.loc[df_col_edges.index[i]]['val']\n",
    "            left_assess_val = df_col_edges.loc[df_col_edges.index[i-1]]['val']\n",
    "            right_assess_val = df_col_edges.loc[df_col_edges.index[i+1]]['val']\n",
    "\n",
    "            width = right_assess_val - left_assess_val # width in the col's dimension if removing edge i\n",
    "            if width > deltas[col]:\n",
    "                continue\n",
    "\n",
    "            # Adjust width for this variables to be comparable with the others\n",
    "            width /= col_scale_factor[col]\n",
    "\n",
    "            # Drop stratum edges for given column that is greater or smaller than what we are assessing \n",
    "            df_assess = df_edges[\n",
    "                ~((df_edges.col == col) & \n",
    "                ((df_edges.val < left_assess_val) | (df_edges.val > right_assess_val)))                \n",
    "            ]\n",
    "\n",
    "            # Also irrelevant units are filtered out for now\n",
    "            tr_filtered = tr[np.where(np.logical_and(tr[:, col] >= left_assess_val, tr[:, col] < right_assess_val))]\n",
    "            ct_filtered = ct[np.where(np.logical_and(ct[:, col] >= left_assess_val, ct[:, col] < right_assess_val))]\n",
    "\n",
    "            # First check strata with the current edge\n",
    "            tr_unmatched_with, ct_unmatched_with, checked_keys = count_unmatched(\n",
    "                df_assess, tr_filtered, ct_filtered, unmatched_counts)\n",
    "\n",
    "            # Then check what happens if we remove the edge (in the middle)\n",
    "            df_assess = df_assess[~((df_assess['val'] == assess_val) & (df_assess['col'] == col))]\n",
    "                \n",
    "            # df_assess = df_assess.drop(df_assess.index[1])\n",
    "            tr_unmatched_without, ct_unmatched_without, _ = count_unmatched(\n",
    "                df_assess, tr_filtered, ct_filtered, unmatched_counts)\n",
    "\n",
    "            tr_match_inc = tr_unmatched_with - tr_unmatched_without\n",
    "            ct_match_inc = ct_unmatched_with - ct_unmatched_without\n",
    "\n",
    "            tr_w = (cur_tr_unmatched - max_tr_unmatched) / (n_tr - max_tr_unmatched)\n",
    "            if (tr_w < 0):\n",
    "                tr_w = 0\n",
    "\n",
    "            ct_w = (cur_ct_unmatched - max_ct_unmatched) / (n_ct - max_ct_unmatched)\n",
    "            if (ct_w < 0):\n",
    "                ct_w = 0\n",
    "                \n",
    "            rel_inc = (tr_match_inc * tr_w) + (ct_match_inc * ct_w)\n",
    "\n",
    "            if (rel_inc > cur_rel_inc) or (rel_inc == cur_rel_inc and width < selected_edge_width):\n",
    "                cur_rel_inc = rel_inc\n",
    "                cur_tr_match_inc = tr_match_inc\n",
    "                cur_ct_match_inc = ct_match_inc\n",
    "                remove_index = df_col_edges.index[i]\n",
    "                selected_edge_width = width\n",
    "                for key in checked_keys:\n",
    "                    unmatched_counts.pop(key)\n",
    "            checked_keys.clear()\n",
    "\n",
    "    if remove_index is not None:\n",
    "        df_edges.drop(remove_index, inplace=True)\n",
    "    else:\n",
    "        print('No more improvements found...')\n",
    "        break\n",
    "\n",
    "    if ((cur_tr_match_inc > 0) or (cur_ct_match_inc > 0)):\n",
    "        cur_tr_unmatched -= cur_tr_match_inc\n",
    "        cur_ct_unmatched -= cur_ct_match_inc\n",
    "        print(f'edges: {len(df_edges)}\\nUnmatched G0: {cur_ct_unmatched}, G1: {cur_tr_unmatched}')\n",
    "\n",
    "    if ((cur_tr_unmatched <= max_tr_unmatched) and (cur_ct_unmatched <= max_ct_unmatched)):\n",
    "        print('Finished!')\n",
    "        break\n",
    "\n",
    "unmatched_counts.clear()    \n",
    "cur_tr_unmatched, cur_ct_unmatched, _ = count_unmatched(df_edges, tr, ct, unmatched_counts)\n",
    "print(f'Num. edges: {len(df_edges)}\\nUnmatched G0: {cur_ct_unmatched}, G1: {cur_tr_unmatched}')\n",
    "# print(df_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_1_cutoffs = df_edges[df_edges['col'] == 0]['val'].to_list()\n",
    "cov_2_cutoffs = df_edges[df_edges['col'] == 1]['val'].to_list()\n",
    "cov_1_cutoffs.sort()\n",
    "cov_2_cutoffs.sort()\n",
    "\n",
    "with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "  call_cem_autostrata = robjects.globalenv['call_cem_autostrata']\n",
    "\n",
    "  dropcols = robjects.StrVector(dropcols)\n",
    "\n",
    "  cutoffs = {}\n",
    "\n",
    "  cutoffs[vname1] = cov_1_cutoffs\n",
    "  cutoffs[vname2] = cov_2_cutoffs\n",
    "\n",
    "  cps_dict = {}\n",
    "  for key in cutoffs:\n",
    "    cps_dict[key] = robjects.FloatVector(cutoffs[key])\n",
    "  cps = robjects.ListVector(cps_dict)\n",
    "\n",
    "  autostrata_res = call_cem_autostrata(df_r, treatedcol, dropcols, cps)\n",
    "\n",
    "  print('Autostrata results')\n",
    "  print(autostrata_res)\n",
    "\n",
    "  print(autostrata_res.rx2('breaks'))\n",
    "\n",
    "  print(autostrata_res.rx2('strata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "full_cov_1_cutoffs = plain_mat.rx2('breaks').rx2(vname1)\n",
    "full_cov_2_cutoffs = plain_mat.rx2('breaks').rx2(vname2)\n",
    "\n",
    "ax1.scatter(tr[:, 0], tr[:, 1], marker='x', label='Treated', c='0.25')\n",
    "ax1.scatter(ct[:, 0], ct[:, 1], marker='.', label='Controls', c='0.25')\n",
    "\n",
    "ax1.vlines(full_cov_1_cutoffs, np.min(full_cov_2_cutoffs), np.max(full_cov_2_cutoffs), colors=['0.5'], linewidth=2)\n",
    "ax1.hlines(full_cov_2_cutoffs, np.min(full_cov_1_cutoffs), np.max(full_cov_1_cutoffs), colors=['0.5'], linewidth=2)\n",
    "ax1.legend(loc=1, framealpha=1, fontsize=14)\n",
    "\n",
    "ax2.scatter(tr[:, 0], tr[:, 1], marker='x', label='Treated', c='0.25')\n",
    "ax2.scatter(ct[:, 0], ct[:, 1], marker='.', label='Controls', c='0.25')\n",
    "\n",
    "ax2.vlines(cov_1_cutoffs, np.min(cov_2_cutoffs), np.max(cov_2_cutoffs), colors=['0.5'], linewidth=2)\n",
    "ax2.hlines(cov_2_cutoffs, np.min(cov_1_cutoffs), np.max(cov_1_cutoffs), colors=['0.5'], linewidth=2)\n",
    "sns.despine(right = True)\n",
    "ax2.legend(loc=1, framealpha=1, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80c3761dc19748af541f56ed624f4219073aeaf847887ec62d1a4bae5734ed4d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jiamatch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
